import nltk
import os

# Stelle sicher, dass punkt an einem beschreibbaren Ort liegt
nltk_data_path = os.path.join(os.getcwd(), "nltk_data")
nltk.data.path.append(nltk_data_path)

# Nur wenn n√∂tig downloaden (um es nicht jedes Mal zu versuchen)
try:
    nltk.data.find("tokenizers/punkt")
except LookupError:
    nltk.download("punkt", download_dir=nltk_data_path)

import streamlit as st
import openai
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext
from llama_index.llms.openai import OpenAI

# API-Key aus Streamlit Secrets
openai.api_key = st.secrets["OPENAI_API_KEY"]

st.title("üê∂ Nasenblick KI")
st.write("Stelle mir deine Frage zur Hundeerziehung!")

query = st.text_input("Was m√∂chtest du wissen?")

if query:
    with st.spinner("Denke nach..."):
        # Dummy: Nur statische Daten lesen (du kannst das sp√§ter mit deinen .md-Dateien erweitern)
        documents = SimpleDirectoryReader("data").load_data()

        service_context = ServiceContext.from_defaults(llm=OpenAI(temperature=0.7))
        index = VectorStoreIndex.from_documents(documents, service_context=service_context)
        response = index.query(query)
        st.success(response.response)
